{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lmfit.models import Model\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pyconll\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UD to txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_conll_file_location = 'hy_bsut-ud-train.conllu'\n",
    "train = pyconll.load_from_file(my_conll_file_location)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('ud_eastern.txt', 'w') as f:\n",
    "    for sentence in train:\n",
    "        # Do work within loops\n",
    "        f.write(sentence.text + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stop-words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    # punctuation=['.','-',',','!','?','(','—',')','՞','՛','։','՝','՜','’','«','»','*','\\n','=',':','[',']','/',';','․','`','\\t','%','$','\\xa0','\\r','_','●','0','1','2','3','4','5','6','7','8','9']\n",
    "    punctuation = ['՜', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '-', '—', '։']\n",
    "\n",
    "    for spaced in punctuation:\n",
    "        sentence = sentence.replace(spaced, '').lower()\n",
    "\n",
    "    sentence = re.sub(\" +\", \" \", sentence)\n",
    "\n",
    "    txt = sentence.replace('\\n', '').lower()\n",
    "    txt = txt.split(' ')\n",
    "    txt = [t for t in txt if t != '']\n",
    "    return txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "folders = ['eastern', 'western', 'grabar']\n",
    "worlds_list_dict = {}\n",
    "\n",
    "for folder in folders:\n",
    "    files_paths = glob.glob(folder + '/*.txt')\n",
    "    names = [path.replace('/', ' ')[:15] for path in files_paths]\n",
    "    files = [' '.join(open(path, 'r', encoding='utf8').readlines()) for path in files_paths]\n",
    "\n",
    "    words_list = []\n",
    "    for sentence in files:\n",
    "        words_list.extend(preprocess(sentence))\n",
    "\n",
    "    print(words_list.__len__())\n",
    "    worlds_list_dict[folder] = Counter(words_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('stop_eastern.txt', 'w') as f:\n",
    "    for i, line in enumerate(worlds_list_dict['eastern'].most_common()):\n",
    "        if line[1] >= 150:\n",
    "            f.write(str(line[0]) + '\\n')\n",
    "        else:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and split data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "folders = ['eastern', 'western', 'grabar']\n",
    "files_dict = {}\n",
    "\n",
    "for folder in folders:\n",
    "    files_paths = glob.glob(folder + '/*.txt')\n",
    "    files = [' '.join(open(path, 'r', encoding='utf8').readlines()) for path in files_paths]\n",
    "    files_dict[folder] = files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "preprocess_files_dict = {}\n",
    "batch_len = 20\n",
    "\n",
    "for folder in folders:\n",
    "    files = files_dict[folder]\n",
    "    batches_list = []\n",
    "\n",
    "    for file in files:\n",
    "        words = preprocess(file)\n",
    "        batches = np.array_split(words, np.ceil(words.__len__() / batch_len))\n",
    "        batches_list.extend(batches)\n",
    "\n",
    "    preprocess_files_dict[folder] = batches_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_text = []\n",
    "dataset_labels = []\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    text_batches = preprocess_files_dict[folder]\n",
    "    dataset_text.extend(text_batches)\n",
    "    dataset_labels.extend(np.full(len(text_batches), i))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lexical (stop-words) descriptors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "western_stop = ['ենք', 'էի', 'թ', 'ին', 'մենք', 'որոնք', 'պիտի', 'և', 'որպեսզի', 'վրայ', 'կ՚', 'կը', 'մը', 'մըն',\n",
    "                'անոր', 'ալ', 'ան', 'քեզ', 'եթէ', 'թէ', 'որպէս']\n",
    "\n",
    "grabar_stop = ['դու', 'եք', 'ըստ', 'նա', 'պիտի', 'վրայ', 'զի', 'ընդ', 'քո', 'քեզ', 'եթէ', 'թէ', 'որպէս']\n",
    "\n",
    "eastern_stop = ['դու', 'ենք', 'եք', 'էի', 'ըստ', 'ին', 'հետո', 'մենք', 'մեջ', 'նա', 'նաև', 'նրա', 'նրանք', 'որը',\n",
    "                'որոնք', 'որպես', 'ում', 'վրա', 'և', 'որպեսզի']\n",
    "\n",
    "western_stop = set(western_stop)\n",
    "grabar_stop = set(grabar_stop)\n",
    "eastern_stop = set(eastern_stop)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_lexical_desc(words):\n",
    "    intersect_western = len(set(words) & western_stop) / len(western_stop)\n",
    "    intersect_grabar = len(set(words) & grabar_stop) / len(grabar_stop)\n",
    "    intersect_eastern = len(set(words) & eastern_stop) // len(eastern_stop)\n",
    "\n",
    "    return intersect_western, intersect_grabar, intersect_eastern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Morphemic descriptors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grabar_suffixes = ['աւք', 'եալ', 'եան', 'իւք', 'ոյց', 'ովք', 'ուց', 'ուցան']\n",
    "grabar_prefixes = ['ապա', 'արտ', 'բաղ', 'բաղա', 'դեր', 'ենթ', 'ենթա', 'ընթա', ' համ', 'համա', 'հան', 'հոմ', 'հոմա',\n",
    "                   'տար', 'տարա']\n",
    "\n",
    "eastern_suffixes = ['աբար', 'ագին', 'ագույն', 'ածո', 'ածու', 'ական', 'ակերտ', 'ային', 'անակ', 'անի', 'անոց', 'անք',\n",
    "                    'ապան', 'ապանակ', 'ապատ', 'ապես', 'աստան', 'ավետ', 'ավուն', 'արան', 'արար', 'արեն', 'արք', 'ացի',\n",
    "                    'ացն-', 'ացու', 'բան', 'բար', 'գին', 'գույն', 'եղեն', 'ենի', 'երեն', 'երորդ', 'եցն-', 'լիկ', 'կերտ',\n",
    "                    'կոտ', 'մունք ', 'յալ', 'յակ', 'յան', 'յանց', 'յուն նախա-', 'ներ', 'նոց', 'ոնք', 'ովին', 'որդ',\n",
    "                    'որեն', 'ոցի', 'ուք', 'պան', 'պանակ', 'ստան', 'ված', 'վածք', 'ավոր', 'վոր', 'ություն', 'ուլ', 'ուկ',\n",
    "                    'ուհի', 'ում', 'ույթ', 'ույր', 'ուն', 'ուտ', 'ուրդ', 'ուց']\n",
    "eastern_prefixes = ['ամենա', 'այսր', 'անդր', 'ապա', 'ավտո', 'արտ', 'արտա', 'բենզա', ', գեր', 'գերա', 'դեր', 'ենթա',\n",
    "                    'եվրա', ' էլեկտրա', 'թեր', 'թերա', 'կենս', 'կինո', 'հակ', 'հակա', 'համ', 'համա', 'հար', 'հարա',\n",
    "                    'հեռա', 'հեռուստա', 'հոմա', 'մակ', 'մակրո', 'միկրո', 'միջ', 'նախ', 'ներ', 'ստոր', 'վեր', 'վերա',\n",
    "                    'տար', 'տարա', 'փոխ', 'քառ', 'քառա']\n",
    "\n",
    "western_reform = ['իլ', 'իուն', 'եան', 'յ', 'օ', 'է', 'յ', 'վո', 'ոյ', 'եա', 'եօ', 'իւ', 'ու', 'ւ,' 'յե', 'եյ', 'զի',\n",
    "                  'եւ', 'ել', 'յուն', 'յան', 'ում', 'ո', 'ե', 'հ', 'ո', 'ույ', 'յա', 'յո', 'յու', 'վ', 'ե', ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create RTF model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(clf.predict([[0, 0, 0, 0]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
