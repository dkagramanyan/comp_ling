{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from copy import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nlu\n",
    "\n",
    "from uniparser_eastern_armenian import EasternArmenianAnalyzer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = EasternArmenianAnalyzer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    all_text=copy(text)\n",
    "    for spaced in ['.','-',',','!','?','(','—',')','՞','՛','։','՝','՜','’','«','»','*']:\n",
    "        all_text = all_text.replace(spaced, ' {0} '.format(spaced))\n",
    "\n",
    "    all_text=all_text.replace('   ',' ')\n",
    "    all_text=all_text.replace('  ',' ')\n",
    "    return all_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open('david_of_sassoun.txt','r',encoding='utf-8') as f:\n",
    "    lines.extend(f.readlines())\n",
    "\n",
    "new_lines=[]\n",
    "all_text=''\n",
    "for i,line in enumerate(lines):\n",
    "    text=line.replace('\\n','')\n",
    "    if len(text)>3 and '[' not in text and ']' not in text:\n",
    "        new_lines.append(text)\n",
    "\n",
    "for line in new_lines:\n",
    "    all_text=all_text+' <START> '+line+ ' <END>'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> Դառնամ , զօղորմին տի տամ * Խանում Ծովինարին , Դառնամ , զօղորմին տի տամ Սանասարին , Բաղդասարին . Դառնամ , զօղորմին տի տամ Քեռի Թորոսիկին . Դառնամ , զօղորմին տի տամ Ականջ արողների ծընողներին ։ <END> <START> ՄԱՍՆ Ա ԿՌԻՎ ԲԱՂԴԱԴԻ ԽԱԼԻՖԱՅԻ ԴԵՄ <END> <START> Ըսկիզբն էր կըռապաշտ Խալիֆան , Մեկ էլ Հայոց Գագիկ թագավոր . Կռապաշտ Խալիֆան Բաղդադ կը նստեր , Գագիկթագավոր ՝ Բերդ - Կապոտին ։ <END> <START> Գագիկ թագավոր ծեր , ալևոր էր . Զինք շա ՛ տ հարըստություն ուներ , Զարմ ու զավակներ չուներ . Մեկ աղջիկ ուներ , շատ տեսակով , Անուն ՝ Ծովինար խանում ։ <END> <START> Էն ժամանակ ո ՛ ր թագավոր զորեղ ըլներ , Էն մեկէլից հարկ կ ’ առներ ։ Բաղդադու Խալիֆան շատ զոր ու զորընդեղ էր . Ասքար արեց , էկավ վեր մեր ազգին . Շատ առ ու ավար առավ , Ու շատ գերի բռնեց տարավ , Շատ ըզմեր ազգ կտրեց , նվազցուց ։ Ու Հայոց Գագիկ թագավոր Բաղդադու Խալիֆային խարջդար էղավ ։ <END> <START> Օրերից մեկ օր Խալիֆան էլավ . Էրկու մարդ հարկ առնող ուղարկեց . <END> <START> — Գնացե ՛ ք , իմ խարջ ժողվեցեք , բերեք ։ Հարկ առնողներն էկան , անցան Թագավորի քոշկ ու սարի առջևեն . Որ կ ’ անցնեին , լուսմի էնոնցէրևաց ։ Իրիշկեցին , ի ՞ նչ տեսնեն , — Էնպես խորոտ աղջիկ մի էրևաց , Արևուն կ ’ ասեր . « Դու դուրս մ ’ էլներ , ե ՛ ս դուրս էլնեմ » ։ Աղջիկ էնպես խորոտ , էնպես խորոտ , Որ տասնուչորս ավուր լուսնին կը նմաներ , Որ յոթ սարի էտևեն կ ’ էլնի ։ Էդ հարկ առնողներ ինչ տեսան զէդ աղջիկ , Խելք գլխըներուց գնաց , Էրկուսն էլ անհուշ , անակահ ընկան ։ Մեկ սհաթեն թագավոր մարդ ուղարկեց , Էկան , զէնոնք տարան իր պալատ ։ <END> <START> Էդ մարդիկն իսկի բան չասին , Էրկուսն էլ էլան , սուս ու փուս դարձան , Իրենց Խալիֆայի մոտ գնացին ։ Խալիֆան հարցուց . — Խարջ բերի ՞ ք ։ Չբերի ՜ ք ։ Ասին . — Թագավոր ապրած կենա , ի ՞ նչ խարջ , ի ՞ նչ բան , Էնպես մեկ բան մ ’ ենք տեսեր , Աղեկ էր մենք չմեռանք ։ Դու ըլնեիր , ավատաս , իրեք ամիս Անհուշ գետին կ ’ ընկնեիր ։ Խալիֆան հարցուց . – Ի ՞ նչ էր ձեր տեսած ։ Էնոնք ասին . — Քո տուն աստված շինի . Դու ի ՞ նչ կ ’ անես ապրանք ու գանձ , հարըստություն . Քեզ ունիս հո ՛ ղ , երկի ՛ ր , ապրա ՛ նք ու գանձ , հարըստությո ՛ ւն , Դու շա ՛ տ ուն\n",
      "Количество символов 374807\n",
      "Количество предложений 4047\n",
      "Количество словоформ 89321\n"
     ]
    }
   ],
   "source": [
    "all_text=format_text(all_text)[1:]\n",
    "\n",
    "corpus_words= [word for word in all_text.split(' ') if word != '']\n",
    "\n",
    "print(all_text[:2000])\n",
    "print(f'Количество символов {len(all_text)}')\n",
    "print(f'Количество предложений',len(all_text.split('։')))\n",
    "print(f'Количество словоформ',len(corpus_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "analyzer = EasternArmenianAnalyzer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество лемм 2176\n"
     ]
    }
   ],
   "source": [
    "lemmas=[]\n",
    "\n",
    "for word in tqdm(corpus_words):\n",
    "    analyses = analyzer.analyze_words(word)[0]\n",
    "    lemmas.append(analyses.lemma)\n",
    "\n",
    "print(f'Количество лемм {len(np.unique(lemmas))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Разобьем на сеты длиной k"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/89317 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "feddd5c5ff894ec7a79206999cc4f979"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 2 # adjustable\n",
    "\n",
    "unique_words = list(np.unique(corpus_words))\n",
    "unique_word2idx = {word: i for i, word in enumerate(unique_words)}\n",
    "# разделим текст на словоформы\n",
    "words_sets = [ ' '.join(corpus_words[i:i+k]) for i, _ in enumerate(corpus_words[:-k]) ]\n",
    "\n",
    "# создадим разряженную матрицу из сетов и словоформ\n",
    "unique_words_sets = list(np.unique(words_sets))\n",
    "sets_count = len(unique_words_sets)\n",
    "\n",
    "# probab_matrix = sparse.dok_matrix((sets_count, len(unique_words)))\n",
    "probab_matrix = np.zeros((sets_count, len(unique_words)))\n",
    "\n",
    "set2idx = {word: i for i, word in enumerate(unique_words_sets)}\n",
    "\n",
    "\n",
    "# пройдемся по сетам и заполним матри\n",
    "for i, set in enumerate(tqdm(words_sets[:-k])):\n",
    "\n",
    "    current_set_idx = set2idx[set]\n",
    "    next_word_idx = unique_word2idx[corpus_words[i+k]]\n",
    "    probab_matrix[current_set_idx, next_word_idx] +=1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "сглаживание 4 лекция"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def generate_sentence(initial_sentence, chain_length=15,alpha=0):\n",
    "    current_set = initial_sentence.split(' ')\n",
    "\n",
    "    sentence = copy(initial_sentence)\n",
    "\n",
    "    for _ in range(chain_length):\n",
    "        sentence+=' '\n",
    "\n",
    "        next_word_vector = probab_matrix[set2idx[' '.join(current_set)]] + alpha\n",
    "        nex_words_probability = next_word_vector/next_word_vector.sum()\n",
    "        next_word = np.random.choice(unique_words, p=nex_words_probability.toarray()[0])\n",
    "\n",
    "        sentence+=next_word\n",
    "        current_set = current_set[1:]+[next_word]\n",
    "    return sentence\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "'<START> Դառնամ , զօղորմին տի տամ * Խանում Ծովինարին , Դառնամ , զօղորմին տի տանք Խանդութ խանումին'"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence('<START> Դառնամ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Сгладим Лаплассом"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "def sentence_probability(initial_sentence, alpha=1, V=2176):\n",
    "\n",
    "    corpus_words= [word for word in initial_sentence.split(' ') if word != '']\n",
    "    words_sets = [ ' '.join(corpus_words[i:i+k]) for i, _ in enumerate(corpus_words[:-k]) ]\n",
    "\n",
    "\n",
    "    log_probab=0\n",
    "\n",
    "    for i,current_set in enumerate(words_sets):\n",
    "\n",
    "        current_set_idx = set2idx.get(current_set)\n",
    "        next_word_idx = unique_word2idx.get(corpus_words[i+k])\n",
    "        if current_set_idx is not None and next_word_idx is not None:\n",
    "            word_number = probab_matrix[current_set_idx,next_word_idx]\n",
    "\n",
    "            next_word_vector = probab_matrix[current_set_idx] + alpha\n",
    "            nex_words_probability = word_number/next_word_vector.sum()\n",
    "        else:\n",
    "            if current_set_idx is not None:\n",
    "                norm=probab_matrix[current_set_idx].sum()\n",
    "            else:\n",
    "                norm=0\n",
    "\n",
    "            nex_words_probability = 1/(norm+V)\n",
    "\n",
    "        log_probab+=np.log(nex_words_probability)\n",
    "\n",
    "    return log_probab\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-37.345002181530795\n",
      "6.043264822079342e-17\n"
     ]
    }
   ],
   "source": [
    "# k=2\n",
    "txt='<START> Դառնամ , զօղորմին տի биба буба'\n",
    "log_prob=sentence_probability(txt)\n",
    "print(log_prob)\n",
    "print(np.exp(log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-28.986442677967325\n",
      "2.578385765817531e-13\n"
     ]
    }
   ],
   "source": [
    "# k=1\n",
    "txt='<START> Դառնամ , զօղորմին տի'\n",
    "log_prob=sentence_probability(txt)\n",
    "print(log_prob)\n",
    "print(np.exp(log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21.967645233959495\n",
      "2.8811966057982644e-10\n"
     ]
    }
   ],
   "source": [
    "# k=2\n",
    "txt='<START> Դառնամ , զօղորմին տի'\n",
    "log_prob=sentence_probability(txt)\n",
    "print(log_prob)\n",
    "print(np.exp(log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.440209514899077\n",
      "1.96970963022116e-07\n"
     ]
    }
   ],
   "source": [
    "# k=3\n",
    "txt='<START> Դառնամ , զօղորմին տի'\n",
    "log_prob=sentence_probability(txt)\n",
    "print(log_prob)\n",
    "print(np.exp(log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Перплексия"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://stackoverflow.com/questions/54941966/how-can-i-calculate-perplexity-using-nltk\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Униграмная модель"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/9554 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8b1e155da074e92967301af7c258c3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity=1.0000897697807196\n"
     ]
    }
   ],
   "source": [
    "pp=0\n",
    "\n",
    "N=89321\n",
    "V=2176\n",
    "for i, set in enumerate(tqdm(probab_matrix)):\n",
    "\n",
    "    word_number=probab_matrix[i, i]\n",
    "    # сглажвание лапласса\n",
    "    if word_number==0:\n",
    "        word_number+=1\n",
    "        word_probab=word_number/(probab_matrix[i].sum()+V)\n",
    "    else:\n",
    "        word_probab=word_number/probab_matrix[i].sum()\n",
    "\n",
    "    pp=np.log(word_probab)\n",
    "\n",
    "l=pp/N\n",
    "print(f'Perplexity={np.power(np.e, -l)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/41976 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47e887822caf4ed4b1386595576d271b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity=1.0000633371299634\n"
     ]
    }
   ],
   "source": [
    "pp=0\n",
    "\n",
    "N=89321\n",
    "V=2176\n",
    "for i, current_set in enumerate(tqdm(unique_words_sets)):\n",
    "\n",
    "    w_old, w_current=current_set.split(' ')\n",
    "    old_idx=unique_word2idx.get(w_old)\n",
    "\n",
    "    old_word_number=probab_matrix[:, old_idx].sum()\n",
    "    current_set_number = probab_matrix[set2idx.get(current_set)].sum()\n",
    "\n",
    "    # сглажвание лапласса\n",
    "    if current_set_number==0:\n",
    "        current_set_number+=1\n",
    "        word_probab=current_set_number/(old_word_number+V)\n",
    "    elif old_word_number==0:\n",
    "        word_probab=current_set_number/(old_word_number+V)\n",
    "    else:\n",
    "        word_probab=current_set_number/old_word_number\n",
    "\n",
    "    pp=np.log(word_probab)\n",
    "\n",
    "l=pp/N\n",
    "print(f'Perplexity={np.power(np.e, -l)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch",
   "language": "python",
   "display_name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}